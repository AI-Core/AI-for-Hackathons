{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning for classification\n",
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def create_csv(root='./data/', out_name='labels.csv'):\n",
    "    subfolders = [f.path for f in os.scandir(root) if f.is_dir()] #get the path of the subfolders in the data root\n",
    "    df = pd.DataFrame(columns=['file_path', 'label']) #create empty dataframe with file_path and label columns\n",
    "    for i, path in enumerate(subfolders):\n",
    "        files = [f.path for f in os.scandir(path) if f.is_file()]\n",
    "        for f in files:\n",
    "            df = df.append({'file_path':f, 'label':i}, ignore_index=True) #add each image as a row to the dataframe\n",
    "    df.to_csv(root+out_name, index=False) #save the dataframe to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "class ClassificationDataset():\n",
    "    def __init__(self, csv='./data/labels.csv', transform=None):\n",
    "        self.csv = pd.read_csv(csv) #read the data csv\n",
    "        self.transform = transform #save the transform variable as part of the class object\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath, label = self.csv['file_path'][idx], self.csv['label'][idx] #get the image filepath and label from at that index from the csv\n",
    "        img = Image.open(filepath).convert(\"RGB\") #open with PIL and convert to rgb\n",
    "        if self.transform:\n",
    "            img, label = self.transform((img, label)) #apply transforms\n",
    "        return img, label\n",
    "\n",
    "class SquareCrop():\n",
    "    \"\"\"Adjust aspect ratio of image to make it square and crop it to given size\"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int)) # assert output_size is integer\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):        \n",
    "        image, label = sample\n",
    "        h, w = image.size\n",
    "        if h>w:\n",
    "            new_w = self.output_size\n",
    "            scale = new_w/w\n",
    "            new_h = scale*h\n",
    "        elif w>h:\n",
    "            new_h = self.output_size\n",
    "            scale = new_h/h\n",
    "            new_w = scale*w\n",
    "        else:\n",
    "            new_h, new_w = self.output_size, self.output_size\n",
    "        new_h, new_w = int(new_h), int(new_w) # account for non-integer computed dimensions (rounds to nearest int)\n",
    "        image = image.resize((new_h, new_w))\n",
    "        crop_start_w=np.random.randint((new_w-self.output_size)+1)\n",
    "        crop_start_h=np.random.randint((new_h-self.output_size)+1)\n",
    "        image = image.crop((crop_start_h, crop_start_w, crop_start_h+self.output_size, crop_start_w+self.output_size))\n",
    "        return image, label\n",
    "\n",
    "class ImageToTensor():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample\n",
    "        image = np.array(image)/255 #convert to numpy array and normalise between 0-1\n",
    "        image = image.transpose((2, 0, 1)) #swap channel dimension\n",
    "        return torch.Tensor(image), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'hotdog', 1: 'dog'}\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "create_csv()\n",
    "\n",
    "classnames = [f.name for f in os.scandir('./data/') if f.is_dir()] #get the class names from the folders\n",
    "classname_to_id = dict(zip(classnames, range(len(classnames)))) #create the mapping from classname to class id\n",
    "id_to_classname = dict(zip(classname_to_id.values(), classname_to_id.keys())) # create the reverse mapping from class id to classname\n",
    "n_classes = len(classnames)\n",
    "print(id_to_classname)\n",
    "\n",
    "img_crop_size = 224\n",
    "train_split = 0.8 # percentage that will be training set\n",
    "val_split = 0.1 #percentage that will be validation set\n",
    "batch_size = 16\n",
    "\n",
    "mytransforms = []\n",
    "mytransforms.append(SquareCrop(img_crop_size)) #add square crop transform\n",
    "mytransforms.append(ImageToTensor()) #add to tensor transform\n",
    "mytransforms = transforms.Compose(mytransforms)\n",
    "\n",
    "mydataset = ClassificationDataset(csv='./data/labels.csv', transform=mytransforms)\n",
    "\n",
    "data_size=len(mydataset)\n",
    "train_size = int(train_split * data_size)\n",
    "val_size = int(val_split * data_size)\n",
    "test_size = data_size - (val_size + train_size)\n",
    "train_data, val_data, test_data = torch.utils.data.random_split(mydataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_samples = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_samples = DataLoader(val_data, batch_size=batch_size)\n",
    "test_samples = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VGGClassifier(torch.nn.Module):\n",
    "    def __init__(self, out_size):\n",
    "        super().__init__()\n",
    "        self.features = models.vgg11(pretrained=True).features #get the convolutional layers of vgg11. output size is 512x7x7\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512*7*7, 4096),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(4096, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, out_size),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.features(x)).reshape(-1, 512*7*7)\n",
    "        x = self.regressor(x)\n",
    "        return x\n",
    "\n",
    "    def freeze(self):\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad=False\n",
    "\n",
    "    def unfreeze(self):\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "lr = [3e-4, 3e-5] #differential learning rate. #lr[0] is main lr #lr[1] is lr of early layers\n",
    "weight_decay = 0#1e-4\n",
    "train_split = 0.8\n",
    "val_split = 0.9\n",
    "\n",
    "mymodel = VGGClassifier(out_size=n_classes).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam([{'params': mymodel.regressor.parameters()},\n",
    "                              {'params': mymodel.features.parameters(), 'lr': lr[1]}],\n",
    "                              lr=lr[0], weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(epochs):\n",
    "    plt.close()\n",
    "    mymodel.train()\n",
    "    \n",
    "    bcosts = []\n",
    "    ecosts = []\n",
    "    valcosts = []\n",
    "    plt.ion()\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    \n",
    "    plt.show()\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Cost')\n",
    "\n",
    "    ax2.axis('off')\n",
    "    img_label_text = ax2.text(0, -5, '', fontsize=15)\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        ecost=0\n",
    "        valcost=0\n",
    "        for i, (x, y) in enumerate(train_samples):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            h = mymodel.forward(x) #calculate hypothesis\n",
    "            cost = F.cross_entropy(h, y, reduction='sum') #calculate cost\n",
    "            \n",
    "            optimizer.zero_grad() #zero gradients\n",
    "            cost.backward() # calculate derivatives of values of filters\n",
    "            optimizer.step() #update parameters\n",
    "\n",
    "            bcosts.append(cost.item()/batch_size)\n",
    "            \n",
    "            y_ind=0\n",
    "            im = np.array(x[y_ind]).transpose(1, 2, 0)\n",
    "            predicted_class = id_to_classname[h.max(1)[1][y_ind].item()]\n",
    "            ax2.imshow(im)\n",
    "            img_label_text.set_text('Predicted class: '+ predicted_class)\n",
    "            \n",
    "            fig.canvas.draw()\n",
    "            ecost+=cost.item()\n",
    "        for i, (x, y) in enumerate(val_samples):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            h = mymodel.forward(x) #calculate hypothesis\n",
    "            cost = F.cross_entropy(h, y, reduction='sum') #calculate cost\n",
    "            y_ind=0\n",
    "            im = np.array(x[y_ind]).transpose(1, 2, 0)\n",
    "            predicted_class = id_to_classname[h.max(1)[1][y_ind].item()]\n",
    "            ax2.imshow(im)\n",
    "            img_label_text.set_text('Predicted class: '+ predicted_class)\n",
    "            fig.canvas.draw()\n",
    "            valcost+=cost.item()\n",
    "        ecost/=train_size\n",
    "        valcost/=val_size\n",
    "        ecosts.append(ecost)\n",
    "        valcosts.append(valcost)\n",
    "        ax.plot(ecosts, 'b', label='Train cost')\n",
    "        ax.plot(valcosts, 'r', label='Validation cost')\n",
    "        if e==0: ax.legend()\n",
    "        fig.canvas.draw()\n",
    "\n",
    "        print('Epoch', e, '\\tCost', ecost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "mymodel.freeze()\n",
    "train(20)\n",
    "#mymodel.unfreeze()\n",
    "#train(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    print('Started evaluation...')\n",
    "    mymodel.eval() #put model into evaluation mode    \n",
    "    #calculate the accuracy of our model over the whole test set in batches\n",
    "    correct = 0\n",
    "    for x, y in test_samples:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        h = mymodel.forward(x)\n",
    "        pred = h.data.max(1)[1]\n",
    "        correct += pred.eq(y).sum().item()\n",
    "    return round(correct/len(test_data), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started evaluation...\n",
      "Test accuracy:  0.9726\n"
     ]
    }
   ],
   "source": [
    "acc = test()\n",
    "print('Test accuracy: ', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
